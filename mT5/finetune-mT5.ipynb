{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook is an example on how to fine tune mT5 model with Higgingface Transformers to solve multilingual task in 101 lanaguges. This notebook especially takes the problem of question generation in hindi lanagues","metadata":{}},{"cell_type":"code","source":"!pip install pytorch_lightning==0.8.1","metadata":{"execution":{"iopub.status.busy":"2023-01-01T09:30:58.805287Z","iopub.execute_input":"2023-01-01T09:30:58.808212Z","iopub.status.idle":"2023-01-01T09:31:08.626521Z","shell.execute_reply.started":"2023-01-01T09:30:58.808165Z","shell.execute_reply":"2023-01-01T09:31:08.625488Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pytorch_lightning==0.8.1\n  Downloading pytorch_lightning-0.8.1-py3-none-any.whl (293 kB)\n\u001b[K     |████████████████████████████████| 293 kB 2.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==0.8.1) (5.3.1)\nRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==0.8.1) (0.18.2)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==0.8.1) (4.45.0)\nRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==0.8.1) (1.18.5)\nRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==0.8.1) (1.6.0)\nRequirement already satisfied: tensorboard>=1.14 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==0.8.1) (2.4.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1) (46.1.3.post20200325)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1) (3.14.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1) (0.4.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1) (2.23.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1) (1.14.0)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1) (1.33.2)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1) (1.14.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1) (1.7.0)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1) (0.11.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1) (1.0.1)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1) (0.34.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1) (3.2.1)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.8.1) (1.2.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.8.1) (2020.11.8)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.8.1) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.8.1) (1.25.9)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.8.1) (2.9)\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1) (4.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1) (0.2.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1) (3.1.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.8.1) (3.0.1)\nRequirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1) (0.4.8)\nInstalling collected packages: pytorch-lightning\n  Attempting uninstall: pytorch-lightning\n    Found existing installation: pytorch-lightning 1.0.6\n    Uninstalling pytorch-lightning-1.0.6:\n      Successfully uninstalled pytorch-lightning-1.0.6\nSuccessfully installed pytorch-lightning-0.8.1\n\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers==4.0.0rc1","metadata":{"execution":{"iopub.status.busy":"2023-01-01T09:31:08.630146Z","iopub.execute_input":"2023-01-01T09:31:08.630477Z","iopub.status.idle":"2023-01-01T09:31:18.206401Z","shell.execute_reply.started":"2023-01-01T09:31:08.630440Z","shell.execute_reply":"2023-01-01T09:31:18.205482Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting transformers==4.0.0rc1\n  Downloading transformers-4.0.0rc1-py3-none-any.whl (1.3 MB)\n\u001b[K     |████████████████████████████████| 1.3 MB 2.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==4.0.0rc1) (1.18.5)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.0.0rc1) (2020.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.0.0rc1) (3.0.10)\nCollecting tokenizers==0.9.4\n  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n\u001b[K     |████████████████████████████████| 2.9 MB 54.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.0.0rc1) (2.23.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.0.0rc1) (0.0.43)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==4.0.0rc1) (20.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.0.0rc1) (4.45.0)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.0.0rc1) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.0.0rc1) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.0.0rc1) (1.25.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.0.0rc1) (2020.11.8)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.0.0rc1) (0.14.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.0.0rc1) (7.1.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.0.0rc1) (1.14.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.0.0rc1) (2.4.7)\nInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.9.2\n    Uninstalling tokenizers-0.9.2:\n      Successfully uninstalled tokenizers-0.9.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 3.4.0\n    Uninstalling transformers-3.4.0:\n      Successfully uninstalled transformers-3.4.0\n\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n\nallennlp 1.2.1 requires transformers<3.5,>=3.1, but you'll have transformers 4.0.0rc1 which is incompatible.\u001b[0m\nSuccessfully installed tokenizers-0.9.4 transformers-4.0.0rc1\n\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"class Config():\n    #paths\n    df_root='../input/xquad'\n    output_dir=\"/kaggle/working/result\"\n\n    \n    #hyperparameters\n    max_seq_length=100\n    learning_rate=3e-4\n    weight_decay=0.0\n    adam_epsilon=1e-8\n    warmup_steps=0\n    train_batch_size=8\n    eval_batch_size=8\n    num_train_epochs=20\n    gradient_accumulation_steps=8\n    n_gpu=1\n    fp_16=False # if you want to enable 16-bit training then install apex and set this to true\n    opt_level='O1'\n    max_grad_norm=1.0\n    \n    #model type\n    model_type=\"small\" # choices small, base, large, xl,xxl","metadata":{"execution":{"iopub.status.busy":"2023-01-01T09:31:18.210149Z","iopub.execute_input":"2023-01-01T09:31:18.210449Z","iopub.status.idle":"2023-01-01T09:31:18.219085Z","shell.execute_reply.started":"2023-01-01T09:31:18.210416Z","shell.execute_reply":"2023-01-01T09:31:18.217109Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"config=Config()","metadata":{"execution":{"iopub.status.busy":"2023-01-01T09:31:18.220193Z","iopub.execute_input":"2023-01-01T09:31:18.220498Z","iopub.status.idle":"2023-01-01T09:31:18.231507Z","shell.execute_reply.started":"2023-01-01T09:31:18.220466Z","shell.execute_reply":"2023-01-01T09:31:18.230706Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport glob\nimport os\nimport json\nimport time\nimport logging\nimport random\nimport re\nfrom itertools import chain\nfrom string import punctuation\nimport matplotlib.pyplot as plt\nimport nltk\nnltk.download('punkt')\nfrom nltk.tokenize import sent_tokenize\n\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pytorch_lightning as pl\nfrom transformers import AdamW, AutoTokenizer, MT5ForConditionalGeneration, get_linear_schedule_with_warmup\nimport transformers","metadata":{"execution":{"iopub.status.busy":"2023-01-01T09:31:18.233925Z","iopub.execute_input":"2023-01-01T09:31:18.234336Z","iopub.status.idle":"2023-01-01T09:31:28.680191Z","shell.execute_reply.started":"2023-01-01T09:31:18.234301Z","shell.execute_reply":"2023-01-01T09:31:28.679126Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n","output_type":"stream"}]},{"cell_type":"code","source":"import argparse\nimport glob\nimport os\nimport json\nimport time\nimport logging\nimport random\nimport re\nfrom itertools import chain\nfrom string import punctuation\nimport matplotlib.pyplot as plt\nimport nltk\nnltk.download('punkt')\nfrom nltk.tokenize import sent_tokenize\n\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pytorch_lightning as pl\nfrom transformers import AdamW, AutoTokenizer, MT5ForConditionalGeneration, get_linear_schedule_with_warmup\nimport transformers\n\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\n\nmy_losses=[]\n\ndef get_dataset(tokenizer, type_path, args):\n    return QuestionDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)\n\nclass T5FineTuner(pl.LightningModule):\n    def __init__(self, hparams):\n        global my_losses\n        my_losses.append(\"start\")\n        super(T5FineTuner, self).__init__()\n        self.hparams = hparams\n        \n        self.my_logs=[]\n        print(self.hparams.train_batch_size)\n\n        self.model = MT5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n        self.tokenizer = AutoTokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n\n    def is_logger(self):\n        return True\n\n    def forward(\n            self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None\n    ):\n        return self.model(\n            input_ids,\n            attention_mask=attention_mask,\n            decoder_input_ids=decoder_input_ids,\n            decoder_attention_mask=decoder_attention_mask,\n            labels=labels,\n        )\n\n    def _step(self, batch):\n        labels = batch[\"target_ids\"]\n        labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n\n        outputs = self(\n            input_ids=batch[\"source_ids\"],\n            attention_mask=batch[\"source_mask\"],\n            labels=labels,\n            decoder_attention_mask=batch['target_mask']\n        )\n\n        loss = outputs[0]\n\n        return loss\n\n    def training_step(self, batch, batch_idx):\n        loss = self._step(batch)\n\n        tensorboard_logs = {\"train_loss\": loss}\n        \n        return {\"loss\": loss, \"log\": tensorboard_logs}\n\n    def training_epoch_end(self, outputs):\n        global my_losses\n        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n        my_losses.append({\"avg_train_loss\": avg_train_loss})\n        return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n\n    def validation_step(self, batch, batch_idx):\n        loss = self._step(batch)\n        return {\"val_loss\": loss}\n\n    def validation_epoch_end(self, outputs):\n        global my_losses\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        tensorboard_logs = {\"val_loss\": avg_loss}\n        my_losses.append({\"avg_val_loss\": avg_loss})\n        return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n\n    def configure_optimizers(self):\n\n        model = self.model\n        no_decay = [\"bias\", \"LayerNorm.weight\"]\n        optimizer_grouped_parameters = [\n            {\n                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n                \"weight_decay\": self.hparams.weight_decay,\n            },\n            {\n                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n                \"weight_decay\": 0.0,\n            },\n        ]\n        optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n        self.opt = optimizer\n        return [optimizer]\n\n    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):\n        if self.trainer.use_tpu:\n            xm.optimizer_step(optimizer)\n        else:\n            optimizer.step()\n        optimizer.zero_grad()\n        self.lr_scheduler.step()\n\n    def get_tqdm_dict(self):\n        tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n\n        return tqdm_dict\n\n    def train_dataloader(self):\n        train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", args=self.hparams)\n        dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True,\n                                num_workers=4)\n        t_total = (\n                (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n                // self.hparams.gradient_accumulation_steps\n                * float(self.hparams.num_train_epochs)\n        )\n        scheduler = get_linear_schedule_with_warmup(\n            self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n        )\n        self.lr_scheduler = scheduler\n        return dataloader\n\n    def val_dataloader(self):\n        val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"valid\", args=self.hparams)\n        return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)\n\nlogger = logging.getLogger(__name__)\n\nclass LoggingCallback(pl.Callback):\n        def __init__(self):\n            super(LoggingCallback, self).__init__()\n            self.logs_info=[]\n            \n        \n        def on_validation_end(self, trainer, pl_module):\n            logger.info(\"***** Validation results *****\")\n            if pl_module.is_logger():\n                  metrics = trainer.callback_metrics\n                  # Log results\n                  for key in sorted(metrics):\n                    if key not in [\"log\", \"progress_bar\"]:\n                      logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n\n        def on_test_end(self, trainer, pl_module):\n            logger.info(\"***** Test results *****\")\n            self.logs_info.append(trainer.callback_metrics)\n            if pl_module.is_logger():\n                metrics = trainer.callback_metrics\n\n                  # Log and save results to file\n                output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n                with open(output_test_results_file, \"w\") as writer:\n                    for key in sorted(metrics):\n                          if key not in [\"log\", \"progress_bar\"]:\n                            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n                            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))\n                            \nargs_dict = dict(\n    data_dir=config.df_root, # path for data files\n    output_dir=config.output_dir, # path to save the checkpoints\n    model_name_or_path='google/mt5-{}'.format(config.model_type),\n    tokenizer_name_or_path='google/mt5-{}'.format(config.model_type),\n    max_seq_length=config.max_seq_length,\n    learning_rate=config.learning_rate,\n    weight_decay=config.weight_decay,\n    adam_epsilon=config.adam_epsilon,\n    warmup_steps=config.warmup_steps,\n    train_batch_size=config.train_batch_size,\n    eval_batch_size=config.eval_batch_size,\n    num_train_epochs=config.num_train_epochs,\n    gradient_accumulation_steps=config.gradient_accumulation_steps,\n    n_gpu=config.n_gpu,\n    fp_16=config.fp_16, # if you want to enable 16-bit training then install apex and set this to true\n    opt_level=config.opt_level, # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n    max_grad_norm=config.max_grad_norm, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n    seed=42\n)\n\nclass QuestionDataset(Dataset):\n    def __init__(self, tokenizer, data_dir, type_path, max_len=30):\n        self.path = os.path.join(data_dir, type_path + '.csv')\n\n        self.english = 'context'\n        self.turkissh = 'question'\n        self.data = pd.read_csv(self.path)\n        path_val=self.path.split(\".\")[-2][-1]\n\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        self.inputs = []\n        self.targets = []\n\n        self._build()\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, index):\n        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n        target_ids = self.targets[index][\"input_ids\"].squeeze()\n\n        src_mask = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n        target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n\n        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n\n    def _build(self):\n        for idx in range(len(self.data)):\n            input_text,output_text= self.data.loc[idx, self.english],self.data.loc[idx, self.turkissh]\n   \n            input_ = \"Turkish Context: %s\" % (input_text)\n            target = \"%s \" %(output_text)\n\n            # tokenize inputs\n            tokenized_inputs = self.tokenizer.batch_encode_plus(\n                [input_], max_length=200, pad_to_max_length=True, return_tensors=\"pt\"\n            )\n            # tokenize targets\n            tokenized_targets = self.tokenizer.batch_encode_plus(\n                [target], max_length=20, pad_to_max_length=True, return_tensors=\"pt\"\n            )\n\n            self.inputs.append(tokenized_inputs)\n            self.targets.append(tokenized_targets)\n\nargs = argparse.Namespace(**args_dict)\n\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(\n    period =1,filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=1\n)\ncallback_history=LoggingCallback()\ntrain_params = dict(\n    accumulate_grad_batches=args.gradient_accumulation_steps,\n    gpus=args.n_gpu,\n    max_epochs=args.num_train_epochs,\n    precision= 16 if args.fp_16 else 32,\n    amp_level=args.opt_level,\n    gradient_clip_val=args.max_grad_norm,\n    checkpoint_callback=checkpoint_callback,\n    callbacks=[callback_history],\n)\nprint (\"Initialize model\")\nmodel = T5FineTuner(args)\ntrainer = pl.Trainer(**train_params)\n\nprint (\" Training model\")\nhistory = trainer.fit(model)\n\nprint (\"training finished\")\n\nprint (\"Saving model\")\nmodel.model.save_pretrained(\"/kaggle/working/result\")\n\nprint (\"Saved model\")\n\n\nmy_losses.pop(0)\nmy_losses.pop(1)\nval_loss=[]\ntrain_loss=[]\nfor i in range(len(my_losses)):\n    if(i%2==0):\n        val_loss.append(float(my_losses[i]['avg_val_loss']))\n    else:\n        train_loss.append(float(my_losses[i]['avg_train_loss']))\n        \n        \nplt.figure(figsize=(10,5))\nplt.title(\"Training and Validation Loss for T5 - {}\".format(config.model_type))\nplt.plot(val_loss,label=\"val\")\nplt.plot(train_loss,label=\"train\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.savefig(\"Training and Validation Loss for T5 - {}.png\".format(config.model_type))\nprint(\"Losses Saved\")","metadata":{"execution":{"iopub.status.busy":"2022-12-29T13:28:36.202050Z","iopub.execute_input":"2022-12-29T13:28:36.202416Z","iopub.status.idle":"2022-12-29T14:47:57.358042Z","shell.execute_reply.started":"2022-12-29T13:28:36.202384Z","shell.execute_reply":"2022-12-29T14:47:57.356934Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nInitialize model\n8\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: Checkpoint directory /kaggle/working/result exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n  warnings.warn(*args, **kwargs)\nGPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nCUDA_VISIBLE_DEVICES: [0]\n","output_type":"stream"},{"name":"stdout","text":" Training model\n","output_type":"stream"},{"name":"stderr","text":"\n  | Name  | Type                        | Params\n------------------------------------------------------\n0 | model | MT5ForConditionalGeneration | 300 M \nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eeac4905aae4b81bc2c39cee49d4924"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\ntraining finished\nSaving model\nSaved model\nLosses Saved\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x360 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"!pip install -U nltk","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:47:57.360595Z","iopub.execute_input":"2022-12-29T14:47:57.360969Z","iopub.status.idle":"2022-12-29T14:48:06.135891Z","shell.execute_reply.started":"2022-12-29T14:47:57.360933Z","shell.execute_reply":"2022-12-29T14:48:06.134897Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Requirement already up-to-date: nltk in /opt/conda/lib/python3.7/site-packages (3.8)\nRequirement already satisfied, skipping upgrade: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk) (2022.10.31)\nRequirement already satisfied, skipping upgrade: joblib in /opt/conda/lib/python3.7/site-packages (from nltk) (0.14.1)\nRequirement already satisfied, skipping upgrade: click in /opt/conda/lib/python3.7/site-packages (from nltk) (7.1.1)\nRequirement already satisfied, skipping upgrade: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk) (4.45.0)\n\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:48:06.139169Z","iopub.execute_input":"2022-12-29T14:48:06.139843Z","iopub.status.idle":"2022-12-29T14:48:13.201958Z","shell.execute_reply.started":"2022-12-29T14:48:06.139789Z","shell.execute_reply":"2022-12-29T14:48:13.200712Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Requirement already satisfied: rouge_score in /opt/conda/lib/python3.7/site-packages (0.1.2)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from rouge_score) (0.11.0)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.14.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.18.5)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from rouge_score) (3.8)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->rouge_score) (0.14.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->rouge_score) (7.1.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk->rouge_score) (4.45.0)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk->rouge_score) (2022.10.31)\n\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu\nfrom nltk.translate.meteor_score import meteor_score\nfrom rouge_score import rouge_scorer\nclass SCORESS():\n    def BLUE_SCORE(self,output,references,n_gram=4):\n        if(n_gram==4):\n            weight=[0,0,0,1]\n        if(n_gram==3):\n            weight=[0,0,1,0]\n        if(n_gram==2):\n            weight=[0,1,0,0]\n        if(n_gram==1):\n            weight=[1,0,0,0]\n        max_score=-1\n        for qt_q in references:\n            reference = [qt_q.split()]\n            bleu_score=sentence_bleu(reference, output.split(),weights=weight)\n            max_score=max(bleu_score,max_score)\n        return max_score\n\n    def ROUGE_SCORE(self,output,references):\n        scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n        max_score_1=-1\n        max_score_l=-1\n        for qt_q in references:\n            scores = scorer.score(qt_q,output)\n            scores['rouge1'].fmeasure\n            scores['rougeL'].fmeasure\n            max_score_1=max(scores['rouge1'].fmeasure,max_score_1)\n            max_score_l=max(scores['rougeL'].fmeasure,max_score_l)     \n\n        return max_score_1, max_score_l\n\n    def METEOR_SCORE(self,output,references):\n        max_score=-1\n        for qt_q in references:\n            reference = [qt_q.split()]\n            my_score=meteor_score(reference, output.split())\n            max_score=max(my_score,max_score)\n        return max_score","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:48:13.203847Z","iopub.execute_input":"2022-12-29T14:48:13.204260Z","iopub.status.idle":"2022-12-29T14:48:13.218336Z","shell.execute_reply.started":"2022-12-29T14:48:13.204224Z","shell.execute_reply":"2022-12-29T14:48:13.217280Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"calculate_score=SCORESS()","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:48:13.221611Z","iopub.execute_input":"2022-12-29T14:48:13.222036Z","iopub.status.idle":"2022-12-29T14:48:13.232658Z","shell.execute_reply.started":"2022-12-29T14:48:13.221997Z","shell.execute_reply":"2022-12-29T14:48:13.231908Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"tr=pd.read_csv(config.df_root+\"/train.csv\")\nvl=pd.read_csv(config.df_root+\"/valid.csv\")\nfrom transformers import MT5ForConditionalGeneration, AutoTokenizer\nmodel = MT5ForConditionalGeneration.from_pretrained(config.output_dir)\ntokenizer = AutoTokenizer.from_pretrained(\"google/mt5-base\")\n","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:48:13.235296Z","iopub.execute_input":"2022-12-29T14:48:13.235603Z","iopub.status.idle":"2022-12-29T14:48:23.413408Z","shell.execute_reply.started":"2022-12-29T14:48:13.235548Z","shell.execute_reply":"2022-12-29T14:48:23.412390Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def greedy_decoding (inp_ids,attn_mask):\n    greedy_output = model.generate(input_ids=inp_ids, attention_mask=attn_mask, max_length=256)\n    Question =  tokenizer.decode(greedy_output[0], skip_special_tokens=True,clean_up_tokenization_spaces=True)\n    return Question.strip().capitalize()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\ncontext_q=dict()\ni=0\nj=0\nwhile (i<len(vl)-2):\n    curr_context=vl[\"context\"][i]\n    context_q[\"Turkish Context: \"+curr_context]=[]\n    for j in range(i,len(vl)):\n        if(curr_context==vl[\"context\"][j]):\n            context_q[\"Turkish Context: \"+curr_context].append(vl[\"question\"][j])\n        else:    \n            i=j\n            break","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:48:23.419380Z","iopub.execute_input":"2022-12-29T14:48:23.419683Z","iopub.status.idle":"2022-12-29T14:48:23.814691Z","shell.execute_reply.started":"2022-12-29T14:48:23.419642Z","shell.execute_reply":"2022-12-29T14:48:23.813654Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu\nblue_score=0\nrouge_L_score=0\nrouge_1_score=0\nmeteor_scoree=0\ncounter=0\nfor article in context_q.keys():\n    encoding = tokenizer.encode_plus(article, return_tensors=\"pt\")\n    input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n    max_score=0\n    output = greedy_decoding(input_ids,attention_masks)\n    blue_score+=calculate_score.BLUE_SCORE(output,context_q[article])\n    rouge1,rougeL=calculate_score.ROUGE_SCORE(output,context_q[article])\n    rouge_L_score+=rougeL\n    rouge_1_score+=rouge1\n    meteor_scoree+=calculate_score.METEOR_SCORE(output,context_q[article])\n        \n    counter+=1","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:48:23.817440Z","iopub.execute_input":"2022-12-29T14:48:23.818158Z","iopub.status.idle":"2022-12-29T14:49:46.885257Z","shell.execute_reply.started":"2022-12-29T14:48:23.818111Z","shell.execute_reply":"2022-12-29T14:49:46.884231Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(\"Blue-4 Score\",blue_score/counter)\nprint(\"Rouge-L Score\",rouge_L_score/counter)\nprint(\"Rouge-1 Score\",rouge_1_score/counter)\nprint(\"Meteor Score\",meteor_scoree/counter)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T14:49:46.886762Z","iopub.execute_input":"2022-12-29T14:49:46.887151Z","iopub.status.idle":"2022-12-29T14:49:46.897432Z","shell.execute_reply.started":"2022-12-29T14:49:46.887113Z","shell.execute_reply":"2022-12-29T14:49:46.896409Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Blue-4 Score 0.6199210375270077\nRouge-L Score 0.3912524624868167\nRouge-1 Score 0.40554353233102347\nMeteor Score 0.259094532434502\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('google/mt5-large')","metadata":{"execution":{"iopub.status.busy":"2023-01-01T09:32:13.481521Z","iopub.execute_input":"2023-01-01T09:32:13.481884Z","iopub.status.idle":"2023-01-01T09:32:16.802217Z","shell.execute_reply.started":"2023-01-01T09:32:13.481850Z","shell.execute_reply":"2023-01-01T09:32:16.801217Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=642.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ddd7eaa88954a46a627d409545ce113"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=4309802.0, style=ProgressStyle(descript…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa54a7e6aada4efdb855dc576901be9c"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=65.0, style=ProgressStyle(description_w…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e207fd2f08742d08a429fff9dbf7ec1"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=376.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"571e80fdb79046b5a1092fe2ac7f45b6"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"input_ = \"Turkish Context: %s\" % (\"İstanbul, Türkiye'nin kalbinde yer alan bir şehir ve aynı zamanda ülkenin en büyük şehridir. İstanbul, Doğu ve Batı kültürlerinin birleştiği bir noktadır ve bu yüzden tarihi ve kültürel değeri olan birçok yer barındırmaktadır. İstanbul, Haliç'te yer alan Boğaziçi Köprüsü ile Avrupa ve Asya kıtaları arasında bir bağ oluşturur. İstanbul ayrıca İstanbul Boğazı ve Marmara Denizi ile çevrili olup, bu nedenle deniz taşımacılığı açısından da önemlidir. İstanbul, İstanbul Üniversitesi gibi ünlü üniversitelerinin de bulunduğu bir eğitim merkezidir.\")","metadata":{"execution":{"iopub.status.busy":"2023-01-01T09:39:06.074207Z","iopub.execute_input":"2023-01-01T09:39:06.074591Z","iopub.status.idle":"2023-01-01T09:39:06.079071Z","shell.execute_reply.started":"2023-01-01T09:39:06.074561Z","shell.execute_reply":"2023-01-01T09:39:06.077945Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"encoded=tokenizer.batch_encode_plus([input_], max_length=200, pad_to_max_length=True, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2023-01-01T09:39:06.406898Z","iopub.execute_input":"2023-01-01T09:39:06.407278Z","iopub.status.idle":"2023-01-01T09:39:06.414479Z","shell.execute_reply.started":"2023-01-01T09:39:06.407245Z","shell.execute_reply":"2023-01-01T09:39:06.413433Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"encoded","metadata":{"execution":{"iopub.status.busy":"2023-01-01T09:39:06.790112Z","iopub.execute_input":"2023-01-01T09:39:06.790445Z","iopub.status.idle":"2023-01-01T09:39:06.800641Z","shell.execute_reply.started":"2023-01-01T09:39:06.790413Z","shell.execute_reply":"2023-01-01T09:39:06.799717Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[   259,  60583,    259,  59315,    267,  17412,    261,   9275,    277,\n           1785,  31471,   8238,   4344,  18463,    698,    259,  23028,    529,\n           1099,  10946,   4808,    407,    259,  17229,   1785,    289,  12533,\n          43870,    286,   6900,    260,  17412,    261,    259, 105339,    529,\n            364,  30045,    408,  48058,  13012, 215627,  62002,    698,  39057,\n          11211,    529,    758,  12448,    880,    259,  60486,    529,    408,\n          48058,    701,  41962,    266,   3143,    698,   3803,   4344,   2373,\n         130400,  18202,    260,  17412,    261,  42456,    993,    277,    346,\n           4344,  18463,   3417,  98343, 139474,  43091,    286,  42145,   2222,\n            259,  39249,    529, 127499,    262,    259,  16779,    422,   1954,\n            259,    262,  10699,    698,  67946, 158111,    286,    260,  17412,\n          26073,    750,  17412,   3417,   8910,  23216,    529,  95871,    262,\n          82714,    266,   2222, 123155,    266,    259,  30192,    261,    758,\n          12895,    468,    259,  46951,  32036,    648,  77138,  39564,  46182,\n            350,  13904,  44014,    260,  17412,    261,  17412,  51429,   6290,\n            259,  94195,    259,  97826,  13012,    269,  13192,  43324,    698,\n          28851,  51371,   6900,    260,      1,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]])}"},"metadata":{}}]},{"cell_type":"code","source":"print(tokenizer.decode(encoded['input_ids'][0]))","metadata":{"execution":{"iopub.status.busy":"2023-01-01T09:39:08.140014Z","iopub.execute_input":"2023-01-01T09:39:08.140359Z","iopub.status.idle":"2023-01-01T09:39:08.146267Z","shell.execute_reply.started":"2023-01-01T09:39:08.140328Z","shell.execute_reply":"2023-01-01T09:39:08.145145Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Turkish Context: İstanbul, Türkiye'nin kalbinde yer alan bir şehir ve aynı zamanda ülkenin en büyük şehridir. İstanbul, Doğu ve Batı kültürlerinin birleştiği bir noktadır ve bu yüzden tarihi ve kültürel değeri olan birçok yer barındırmaktadır. İstanbul, Haliç'te yer alan Boğaziçi Köprüsü ile Avrupa ve Asya kıtaları arasında bir bağ oluşturur. İstanbul ayrıca İstanbul Boğazı ve Marmara Denizi ile çevrili olup, bu nedenle deniz taşımacılığı açısından da önemlidir. İstanbul, İstanbul Üniversitesi gibi ünlü üniversitelerinin de bulunduğu bir eğitim merkezidir.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}